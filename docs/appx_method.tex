\chapter{方法实现细节补充}
\label{appx:method}

本附录对第\ref{chap:method}章的关键实现细节进行补充，重点覆盖数据管线、模块接口、训练调度与工程落地细节，目标是提升方法复现性与可迁移性。

\section{数据管线与样本构造}
\subsection{轨迹切片规则}
为统一训练样本构造，本文采用前缀预测范式：给定用户轨迹 $\mathcal{T}_u=\{x_1,\ldots,x_n\}$，构造训练样本为：
\begin{equation}
(\{x_1,\ldots,x_t\}, x_{t+1}),\quad t\in[1,n-1].
\end{equation}
式中：\symline{$\{x_1,\ldots,x_t\}$}{历史前缀轨迹；\\}
\hphantom{式中：}\symline{$x_{t+1}$}{监督目标下一点；\\}
\hphantom{式中：}\symline{$t\in[1,n-1]$}{切片索引范围。\\}
该构造与在线推荐流程一致，可避免后缀信息泄露。

\subsection{时间槽映射}
对于时间戳 $t_i$，先转换为本地时间，再映射到时间槽索引 $z_i\in\{1,\ldots,Z\}$。在实现中，建议将工作日与休息日使用统一映射规则并附加二值指示位，以减少节律冲突。

\subsection{候选集合构建}
候选集合由“全局候选 + 局部地理候选 + 高频回访候选”组成。该策略可在不牺牲召回覆盖的前提下控制打分开销。实际部署时可将全量候选打分替换为两级召回架构。

\section{TSPM分支实现细节}
\subsection{模块输入输出接口}
TSPM输入包括三类张量：POI索引序列、时间槽索引序列、用户索引。输出为候选POI得分向量与中间结构表示（用于与LLM侧对齐）。推荐的接口形式如下：
\begin{itemize}
    \item 输入：\texttt{poi\_seq[B,L]}，\texttt{time\_slot[B,L]}，\texttt{user\_id[B]}；
    \item 输出：\texttt{score\_tspm[B,N]}，\texttt{h\_seq[B,d]}，\texttt{h\_graph[B,d]}。
\end{itemize}

\subsection{动态图更新策略}
动态图可按两种策略更新：
\begin{enumerate}
    \item \textbf{离线静态近似更新}：每个epoch后批量更新图权重，训练稳定、实现简单；
    \item \textbf{在线增量更新}：按批次局部更新邻接权重，能更快响应新分布但开销更高。
\end{enumerate}
本文优先采用第一种方式，在稳定性与效率之间更均衡。

\subsection{负采样实践建议}
负采样按“难负样本优先”原则构造：
\begin{enumerate}
    \item 从同区域抽取地理相近但真实未访问POI；
    \item 从同类别抽取语义相近POI；
    \item 从全局抽取随机负样本维持分布多样性。
\end{enumerate}
在实践中，可采用分段比例策略控制三类负样本占比，避免训练被单一难样本主导。

\section{GCIM与PAM实现细节}
\subsection{GCIM编码流水线}
GCIM编码建议按以下步骤执行：
\begin{enumerate}
    \item 经纬度归一化，缓解量纲差异；
    \item Quadkey层级映射，生成离散区域编码；
    \item Fourier频域投影，增强连续位置敏感性；
    \item 多层感知器融合，映射到LLM可接收维度。
\end{enumerate}
上述流程中，归一化与层级映射顺序不建议交换，否则会导致空间层级边界解释不一致。

\subsection{PAM对齐机制}
PAM负责将POI结构表示投影至LLM语义空间。实现中可采用线性投影或两层MLP投影。线性投影参数更少、稳定性更好；两层MLP表达力更强但更易过拟合。本文优先采用线性方案作为主设置。

\subsection{联合注入策略}
在提示构造阶段，建议将`<GPS>`与`<POI>`token固定在统一字段顺序中，避免模板漂移。训练与推理应共享同一模板，减少分布偏移导致的性能回退。

\section{两阶段训练调度细节}
\subsection{阶段一：表示对齐}
阶段一冻结LLM主体，仅优化GCIM/PAM及映射层，目标是最小化对齐损失与地理一致性损失。该阶段重点在于建立跨空间可读表示，而非追求最终任务最优。

\subsection{阶段二：协同优化}
阶段二引入LoRA微调并联合优化任务目标。为提升稳定性，建议采用分段学习率：对齐模块较大学习率，LLM-LoRA较小学习率。该设置可避免语义模型过快覆盖已学结构先验。

\subsection{早停与检查点策略}
建议按验证集MRR与Acc@1联合监控：若二者连续若干轮无提升则触发早停。检查点保存采用“最优性能 + 最近轮次”双副本策略，便于回溯与故障恢复。

\section{推理与部署细节}
\subsection{重排序触发条件}
对于时延敏感场景，可仅在以下条件触发协同重排序：
\begin{enumerate}
    \item LLM前两名候选得分接近（不确定性高）；
    \item 用户轨迹呈现跨区域迁移迹象；
    \item 当前样本属于冷启动或长尾类别。
\end{enumerate}
按需触发可降低平均推理开销。

\subsection{缓存与增量更新}
在线系统可对高频用户与高频区域建立候选缓存，并在小时级或天级执行增量更新。该策略可显著降低重复计算成本，提高系统吞吐。

\subsection{异常回退机制}
当地理信息缺失、模板解析失败或模型服务超时时，建议回退至轻量基线（如TSPM-only）保证服务可用性。这一机制对工程稳定性至关重要。

\section{实现清单与复现建议}
建议在仓库中固定以下内容：
\begin{enumerate}
    \item 数据清洗脚本、切分索引与版本哈希；
    \item 训练配置文件（含随机种子、学习率、损失权重）；
    \item 评估脚本与指标实现单元测试；
    \item 关键实验日志与模型检查点命名规范。
\end{enumerate}

从论文写作角度看，完整给出上述实现细节能够体现研究工作的可执行性、可复验性和工程严谨性，也是毕业论文中“研究态度端正”的重要组成部分。
