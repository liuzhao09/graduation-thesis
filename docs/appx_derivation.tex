\chapter{关键公式推导与理论讨论补充}
\label{appx:derivation}

本附录补充本文关键损失函数、融合策略与复杂度表达的推导思路，重点回答“这些设计为何合理、优化时关注什么、边界条件是什么”。

\section{双向转移损失推导补充}
\subsection{目标函数重述}
第\ref{chap:method}章中，双向转移损失可写为：
\begin{equation}
\mathcal{L}_{time}=-\sum_t \log\sigma\left(d^-_t-d^+_t\right),
\end{equation}
式中：\symline{$\mathcal{L}_{time}$}{双向转移损失；\\}
$d^-_t,d^+_t$ 分别表示负样本与正样本距离项。\\
距离项定义为：
\begin{equation}
d^+_t=\|\boldsymbol{\xi}^{out}_{i,T}-\boldsymbol{\xi}^{in}_{+,T}\|_2^2,\quad
d^-_t=\|\boldsymbol{\xi}^{out}_{i,T}-\boldsymbol{\xi}^{in}_{-,T}\|_2^2.
\end{equation}
式中：\symline{$\boldsymbol{\xi}^{out}_{i,T}$}{当前POI在时间槽 $T$ 的转出表示；\\}
$\boldsymbol{\xi}^{in}_{+,T},\boldsymbol{\xi}^{in}_{-,T}$ 分别表示正负样本转入表示；\\
\hphantom{式中：}\symline{$\|\cdot\|_2^2$}{平方欧氏距离。\\}
该目标本质上是对“正负距离差”进行最大化。

\subsection{梯度方向解释}
对正样本距离 $d^+_t$ 求偏导可得其梯度方向倾向于减小正样本距离；对负样本距离 $d^-_t$ 的梯度方向倾向于增大负样本距离。由于两者在同一差值中耦合，优化过程会同时增强判别边界与表示紧致性。

\subsection{与单向建模对比}
若只建模转出关系，目标仅约束“从当前点出发”的方向信息；加入转入关系后，模型还能利用“目标点通常从何处到达”的结构统计，从而在路径歧义场景中提升稳定性。

\section{序列对比损失推导补充}
\subsection{损失定义}
序列损失采用与双向损失相似的对比形式：
\begin{equation}
\mathcal{L}_{seq}=-\sum_t \log\sigma\left(\|\boldsymbol{\xi}_{seq}-\mathbf{e}_t^-\|_2^2-\|\boldsymbol{\xi}_{seq}-\mathbf{e}_{t+1}^+\|_2^2\right).
\end{equation}
式中：\symline{$\mathcal{L}_{seq}$}{序列对比损失；\\}
\hphantom{式中：}\symline{$\boldsymbol{\xi}_{seq}$}{历史序列聚合表示；\\}
$\mathbf{e}_t^-,\mathbf{e}_{t+1}^+$ 分别表示负样本与真实下一POI嵌入。

\subsection{优化含义}
该目标推动序列表征靠近真实下一点并远离负样本点。与交叉熵相比，对比损失更关注“相对排序关系”，与Top-$K$推荐目标更一致。

\subsection{边界情况讨论}
当负样本过于简单时，损失很快饱和，难以继续提供有效梯度；当负样本过难且标注噪声高时，可能导致优化震荡。因此实际训练中需平衡负样本难度分布。

\section{协同融合打分讨论}
\subsection{线性融合合理性}
本文采用如下融合打分函数：
\begin{equation}
s(\ell)=\eta s_{llm}(\ell)+(1-\eta)s_{tspm}(\ell)
\end{equation}
式中：\symline{$s(\ell)$}{候选POI $\ell$ 的融合分数；\\}
\hphantom{式中：}\symline{$s_{llm}(\ell)$}{大模型分支打分；\\}
\hphantom{式中：}\symline{$s_{tspm}(\ell)$}{小模型分支打分；\\}
\hphantom{式中：}\symline{$\eta$}{融合系数。\\}
作为推理阶段融合方式。线性融合的优点是可解释、可调、部署简单。其不足是难以捕捉复杂非线性交互，但在工程上具有较高稳定性与可控性。

\subsection{融合系数选择}
当任务强调语义泛化（如冷启动）时，可提高 $\eta$；当任务强调结构稳定性（如高频规律场景）时，可降低 $\eta$。在实际系统中也可按用户分群或场景分群动态设定 $\eta$。

\subsection{归一化问题}
由于两分支打分尺度可能不同，融合前应进行分数归一化，否则易出现某一分支“数值主导”问题。常见做法包括温度缩放、z-score归一化或分位数归一化。

\section{地理一致性约束讨论}
\subsection{约束动机}
LLM语义空间并不天然满足地理距离单调性，即语义邻近不必然对应空间邻近。地理一致性约束的目标是为语义空间加入“弱几何先验”，降低远跳型错误。

\subsection{约束强度选择}
约束权重过低时，校正作用不足；过高时，模型可能过度保守，牺牲语义泛化。实践中建议在验证集上采用分段搜索，并结合错误类型分析决定最终权重。

\section{复杂度表达补充}
\subsection{训练复杂度主导项}
在协同框架中，LLM前向与反向仍是主要开销来源。TSPM与对齐模块虽增加额外计算，但相对于大模型主干开销可控。LoRA的意义在于限制可训练参数规模，减少优化器状态内存。

\subsection{推理复杂度拆分}
推理成本可拆为三部分：输入编码、LLM推理、协同重排序。若业务时延敏感，可控制重排序候选规模；若业务精度优先，可适度扩大候选并进行更充分重排。

\subsection{扩展到大规模场景}
在百万级POI场景下，建议引入分层召回与近似检索，以避免全量打分。协同框架可作为重排层使用，从而在可控成本下保持高精度。

\section{稳定性与泛化讨论}
\subsection{训练稳定性来源}
本文采用两阶段训练与模块解耦，可减少不同目标之间的梯度冲突。对齐阶段建立可读表示，协同阶段再优化任务指标，这种“先表示、后任务”流程可提升收敛稳定性。

\subsection{泛化能力来源}
小模型提供结构偏置，大模型提供语义泛化，两者结合后对跨场景变化更具适应性。特别在长尾与冷启动场景中，协同策略较单路线更具鲁棒性。

\subsection{潜在失败模式}
若数据分布发生剧烈漂移或外部上下文缺失，模型仍可能出现性能回退。后续可通过在线增量学习、外部信号注入和不确定性估计进一步缓解。

\section{本附录小结}
本附录从推导与理论讨论角度补充了方法设计依据。核心结论是：本文关键模块并非经验拼接，而是围绕“排序目标一致性、地理约束合理性、训练稳定性与部署可控性”展开的系统化设计。该补充有助于读者从理论与工程两端理解本文方案的有效性与边界条件。
