\chapter{实验设计与结果分析}
\label{chap:exp}

\section{本章引言}
本章围绕第\ref{chap:method}章提出的双路线研究框架开展系统实验，目标是回答“方法是否有效、为何有效、代价是否可接受”。为避免结果堆叠而缺乏论证链，本章按照“研究问题定义（RQ）—实验设置—主结果—模块消融—机制诊断—效率评估”的闭环组织证据，并确保每类结论都能回溯到对应模块设计与实验现象。

\section{实验目标与研究问题}
本章围绕“双路线方法是否有效、为何有效、代价如何”展开评估，定义如下研究问题：
\begin{enumerate}
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}RQ1（总体有效性）：}相比序列、图和LLM基线，TSPM与GA-LLM两条路线是否均能稳定提升性能？
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}RQ2（小模型机制）：}TSDG、双向转移与动态图权重等设计是否带来独立增益？
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}RQ3（大模型机制）：}GCIM与PAM是否有效缓解空间幻觉并提升冷启动/跨城泛化？
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}RQ4（互补有效性）：}两条路线在误差类型上是否呈现可解释互补，关键错误是否得到改善？
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}RQ5（效率与部署）：}该框架在时间、显存与参数开销上是否具备可部署性？
\end{enumerate}

\section{实验设置}
\subsection{数据集与预处理}
为避免“母数据集”和“城市子集”混用造成理解混乱，本文先给出统一口径。原始公开数据源包括：Gowalla\footnote{\url{http://snap.stanford.edu/data/loc-gowalla.html}} 与 Foursquare\footnote{\url{https://sites.google.com/site/yangdingqi/home}}。其中，Gowalla 时间跨度为 2009 年 2 月至 2010 年 10 月；Foursquare 时间跨度为 2012 年 4 月至 2014 年 1 月。两者均包含用户ID、POI ID、时间戳、经纬度与类别信息。

\topichead{两条模型路线的数据使用差异}
{\heiti\addCJKfontfeatures{AutoFakeBold=2}TSPM路线：}使用母数据集 Gowalla 与 Foursquare 进行训练与评估，侧重验证“时间分槽 + 双向转移 + 动态图”在通用 Next POI 场景下的有效性。\\
{\heiti\addCJKfontfeatures{AutoFakeBold=2}GA-LLM路线：}使用城市/区域子集 NYC、TKY、CA，其中 NYC（New York City, United States）与 TKY（Tokyo, Japan）由 Foursquare 按城市切分得到，CA（California, United States）由 Gowalla 按区域切分得到；其时间范围分别继承对应母数据集的原始时间跨度\cite{LLM4POI}。该设置主要用于评估大模型在“跨城市分布差异、长尾与地理泛化”条件下的表现。

预处理遵循统一 Next POI 协议：过滤签到次数少于10的用户与POI、按时间排序构造轨迹，并采用时间顺序的 80\%/10\%/10\% 训练-验证-测试划分，避免信息泄露\cite{LLM4POI,GETNext,STHGCN}。

表\ref{tab:c4-datasets-icde}给出三组城市/区域级数据统计，体现了“高密度（NYC, 纽约）—多样结构（TKY, 东京）—稀疏广域（CA, 加州）”三种典型难度场景。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{GA-LLM实验数据集统计}{Statistics of datasets used in GA-LLM experiments.}
    \label{tab:c4-datasets-icde}
    \begin{tabular}{lcccc}
        \toprule
        数据集 & 用户数 & POI数 & 类别数 & 签到数 \\
        \midrule
        NYC & 1,048 & 4,981 & 318 & 103,941 \\
        TKY & 2,282 & 7,833 & 290 & 405,000 \\
        CA & 3,957 & 9,690 & 296 & 238,369 \\
        \bottomrule
    \end{tabular}
\end{table}

\keytag{数据清洗策略}\quad
为保证不同方法比较公平，本文在预处理阶段统一执行以下清洗步骤：异常时间戳剔除、重复签到合并、经纬度缺失样本过滤、低频噪声POI裁剪。对于同一用户连续短时间重复签到，按规则合并为单次访问，以避免对短周期“刷点行为”过拟合。

\keytag{轨迹构造原则}\quad
轨迹切片采用时间有序滑窗方式构造监督样本：以前缀历史预测下一点。该构造方式与真实推荐流程一致，可避免随机打乱导致的时间泄露。对于超长轨迹，采用固定窗口与可变窗口结合策略，兼顾长期信息保留与训练稳定性。

\subsection{评价指标与计算协议}
指标采用 Acc@1、Acc@5、Acc@10、MRR 与 NDCG@K。设第 $i$ 个测试样本中真实POI排名为 $rank_i$，对应指标定义为：
\begin{equation}
\text{Acc@k}=\frac{1}{N}\sum_{i=1}^{N}\mathbb{I}(rank_i\le k),\qquad
\text{MRR}=\frac{1}{N}\sum_{i=1}^{N}\frac{1}{rank_i}.
\label{eq:c4-metrics}
\end{equation}
式中：\symline{$N$}{测试样本总数；\\}
\hphantom{式中：}\symline{$rank_i$}{第 $i$ 个样本中真实POI的排名位置；\\}
\hphantom{式中：}\symline{$\mathbb{I}(rank_i\le k)$}{是否命中Top-$k$的指示函数；\\}
\hphantom{式中：}\symline{$\frac{1}{rank_i}$}{该样本的倒数排名得分。\\}
NDCG@K与第\ref{chap:related}章定义一致。对于LLM路线，另报告 MRR@5 评估前五候选排序质量，以适配生成式推荐的输出机制。
需要说明的是：传统基线按全候选列表报告标准 MRR；GA-LLM 路线按生成式输出口径报告 MRR@5。为保证比较公平，本文在对应表格中显式标注指标口径，不将二者混写为同一指标。

\topichead{统计显著性与稳健性}
除主指标外，本文对关键对比结果进行显著性检验，并在不同随机种子下重复实验，以避免“单次最优偶然性”。具体地，每个核心模型在每个数据集上使用 5 个随机种子重复训练与评测，报告 mean$\pm$std；显著性采用 paired t-test，对 Acc@1、Acc@5 与 MRR@5 做成对检验，阈值设为 $p<0.05$。对于方差较大的设置，报告平均趋势并结合误差分析解释波动来源，而非仅展示最优结果。

\subsection{对比方法与分组}
基线分为三组：
\begin{enumerate}
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}序列方法：}FPMC、PRME、LSTM、ST-RNN、STAN 等\cite{FPMC,PRME,LSTM,ST-RNN,STAN};
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}图与时空方法：}STGCN、GETNext、MTNet、STHGCN、ROTAN、Graph-Flashback 等\cite{GETNext,STHGCN,MTNet,ROTAN,GraphFlashback};
    \item {\heiti\addCJKfontfeatures{AutoFakeBold=2}LLM方法：}LLM4POI、E4SRec 与本文GA-LLM\cite{LLM4POI,E4SRec}。
\end{enumerate}
主比较对象分别为TSPM与GA-LLM主模型；小模型与大模型分支结果分别用于回答RQ2与RQ3。

\subsection{实现细节与统计检验}
训练阶段采用两阶段策略：先对齐后协同；LLM侧使用LoRA进行参数高效微调。核心设置为：学习率 $2\times10^{-5}$、warm-up 20 steps、batch size=1/GPU、最大长度32768、训练3 epochs、Quadkey层级$L=25$。小模型侧采用第\ref{chap:method}章给出的统一训练协议。每组实验重复多次并报告平均结果；显著性分析用于验证相对提升的稳定性。

\topichead{超参数搜索范围}
本文对关键超参数采用分层搜索：先粗粒度确定可行区间，再细粒度搜索最优点。重点搜索参数包括时间槽数量、beam size、输出Top-$K$规模、负采样比例、LoRA秩与学习率。该流程保证“模型改进来源于机制设计”而非超参数偶然命中。

\topichead{训练资源与复现实务}
实验统一在固定软硬件环境下运行，记录依赖版本、随机种子和数据切分索引。对可复现实验提供统一脚本入口，确保主结果、消融结果与诊断结果由同一评估代码生成，避免评估实现差异引入偏差。

\section{主结果：双路线模型与基线对比（RQ1）}
\subsection{小模型路线主结果}
表~\ref{tab:tspm-main} 展示了TSPM在Gowalla与Foursquare上的核心结果。可见 TSPM 相较代表性序列/图基线取得稳定增益，说明时间增强与双向转移设计有效。
以最强基线 Graph-Flashback 为参照，TSPM 在 Gowalla 上取得 \redbf{Acc@1 +5.49\%}、\bluebf{MRR +3.59\%}；在 Foursquare 上取得 \redbf{Acc@1 +4.53\%}、\bluebf{MRR +3.99\%}。这说明改进不仅提升“是否命中”，也提升“命中的排序位置”。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{TSPM与基线在Gowalla/Foursquare上的结果（相对最强非本文基线的提升经 paired t-test 检验达到显著水平，$p<0.05$）}{Results of TSPM and baselines on Gowalla and Foursquare (improvements over the strongest non-ours baseline are significant under paired t-test, $p<0.05$).}
    \label{tab:tspm-main}
        \resizebox{\textwidth}{!}{
        \begin{tabular}{lcccccccc}
        \toprule
        \multirow{2}{*}{方法} & \multicolumn{4}{c}{Gowalla} & \multicolumn{4}{c}{Foursquare} \\
        & Acc@1 & Acc@5 & Acc@10 & MRR & Acc@1 & Acc@5 & Acc@10 & MRR \\
        \midrule
        PRME & 0.0740 & 0.2146 & 0.2899 & 0.1503 & 0.0982 & 0.3167 & 0.4064 & 0.2040 \\
        STRNN & 0.0900 & 0.2120 & 0.2730 & 0.1508 & 0.2290 & 0.4310 & 0.5050 & 0.3248 \\
        DeepMove & 0.0625 & 0.1304 & 0.1594 & 0.0982 & 0.2400 & 0.4319 & 0.4742 & 0.3270 \\
        LBSN2Vec & 0.0864 & 0.1186 & 0.1390 & 0.1032 & 0.2190 & 0.3955 & 0.4621 & 0.2781 \\
        STGN & 0.0624 & 0.1586 & 0.2104 & 0.1125 & 0.2094 & 0.4734 & 0.5470 & 0.3283 \\
        LightGCN & 0.0428 & 0.1439 & 0.2115 & 0.1224 & 0.0540 & 0.1790 & 0.2710 & 0.1574 \\
        Flashback & 0.1158 & 0.2754 & 0.3479 & 0.1925 & 0.2496 & 0.5399 & 0.6236 & 0.3805 \\
        STAN & 0.0891 & 0.2096 & 0.2763 & 0.1523 & 0.2265 & 0.4515 & 0.5310 & 0.3420 \\
        GETNext & 0.1419 & 0.3270 & 0.4081 & 0.2294 & 0.2646 & 0.5640 & 0.6431 & 0.3988 \\
        Graph-Flashback & 0.1512 & 0.3425 & 0.4256 & 0.2422 & 0.2805 & 0.5757 & 0.6514 & 0.4136 \\
        \midrule
        TSPM & \textbf{0.1595} & \textbf{0.3520} & \textbf{0.4350} & \textbf{0.2509} & \textbf{0.2932} & \textbf{0.5978} & \textbf{0.6768} & \textbf{0.4301} \\
        \rowcolor{TokBg}
        提升（\%） & +5.49\% & +2.77\% & +2.21\% & +3.59\% & +4.53\% & +3.84\% & +3.90\% & +3.99\% \\
        \bottomrule
    \end{tabular}}
\end{table}

\subsection{大模型路线主结果}
表\ref{tab:c4-gallm-main}展示GA-LLM在NYC/TKY/CA上的主结果。相较于传统模型、图模型以及文本LLM基线，GA-LLM在三座城市均获得最优Acc@1/Acc@5/MRR@5，说明“地理注入+转移对齐”对LLM路线是稳定有效的。
相对最强非GA基线，GA-LLM 在三城的 Acc@1 提升分别为 \redbf{18.27\%（NYC）}、\redbf{14.73\%（TKY）}、\redbf{16.69\%（CA）}；Acc@5 提升最高达到 \bluebf{24.10\%（CA）}。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{GA-LLM在NYC、TKY、CA上的主结果（最佳加粗，次优下划线；相对最强非本文基线的提升经 paired t-test 检验达到显著水平，$p<0.05$）}{Main results of GA-LLM on NYC, TKY, and CA (best in bold, second-best underlined; improvements over the strongest non-ours baseline are significant under paired t-test, $p<0.05$).}
    \label{tab:c4-gallm-main}
        \resizebox{\textwidth}{!}{
        \begin{tabular}{lccccccccc}
        \toprule
        \multirow{2}{*}{模型} & \multicolumn{3}{c}{NYC} & \multicolumn{3}{c}{TKY} & \multicolumn{3}{c}{CA} \\
        & Acc@1 & Acc@5 & MRR@5 & Acc@1 & Acc@5 & MRR@5 & Acc@1 & Acc@5 & MRR@5 \\
        \midrule
        FPMC & 0.1003 & 0.2126 & 0.1701 & 0.0814 & 0.2045 & 0.1344 & 0.0383 & 0.0702 & 0.0911 \\
        LSTM & 0.1305 & 0.2719 & 0.1857 & 0.1335 & 0.2728 & 0.1834 & 0.0665 & 0.1306 & 0.1201 \\
        PRME & 0.1159 & 0.2236 & 0.1712 & 0.1052 & 0.2278 & 0.1786 & 0.0521 & 0.1034 & 0.1002 \\
        ST-RNN & 0.1483 & 0.2923 & 0.2198 & 0.1409 & 0.3022 & 0.2212 & 0.0799 & 0.1423 & 0.1429 \\
        STGCN & 0.1799 & 0.3425 & 0.2788 & 0.1716 & 0.3453 & 0.2504 & 0.0961 & 0.2097 & 0.1712 \\
        CLSPRec & 0.1784 & 0.3830 & 0.2691 & 0.1453 & 0.3394 & 0.2340 & 0.0891 & 0.1815 & 0.1302 \\
        PLSPL & 0.1917 & 0.3678 & 0.2806 & 0.1889 & 0.3523 & 0.2542 & 0.1072 & 0.2278 & 0.1847 \\
        STAN & 0.2231 & 0.4582 & 0.3253 & 0.1963 & 0.3798 & 0.2852 & 0.1104 & 0.2348 & 0.1869 \\
        GETNext & 0.2435 & 0.5089 & 0.3621 & 0.2254 & 0.4417 & 0.3262 & 0.1357 & 0.3278 & 0.2103 \\
        MTNext & 0.2620 & 0.5381 & 0.3855 & 0.2575 & 0.4977 & 0.3659 & 0.1453 & 0.3419 & 0.2367 \\
        STHGCN & 0.2734 & 0.5361 & 0.3915 & 0.2950 & 0.5207 & 0.3986 & 0.1730 & 0.3529 & 0.2558 \\
        ROTAN & \underline{0.3106} & \underline{0.5281} & \underline{0.4104} & 0.2458 & 0.4626 & 0.3475 & \underline{0.2199} & \underline{0.3718} & \underline{0.2931} \\
        LLM4POI\textsuperscript{$\dagger$} & 0.3372 & -- & -- & 0.3035 & -- & -- & 0.2065 & -- & -- \\
        \midrule
        GA-LLM & \textbf{0.3988} & \textbf{0.6337} & \textbf{0.4663} & \textbf{0.3482} & \textbf{0.6207} & \textbf{0.4314} & \textbf{0.2566} & \textbf{0.4614} & \textbf{0.3340} \\
        \rowcolor{TokBg}
        提升（\%） & +18.27\% & +17.77\% & +12.62\% & +14.73\% & +19.20\% & +8.23\% & +16.69\% & +24.10\% & +13.95\% \\
        \bottomrule
    \end{tabular}}

    \vspace{2pt}
    {\footnotesize $\dagger$\,LLM4POI原文仅报告Acc@1，未提供Acc@5与MRR@5，故以"--"标记。}
\end{table}

表\ref{tab:c4-gallm-main}最后一行已汇总GA-LLM相对最强非GA基线的提升比例。三个城市在Acc@1、Acc@5、MRR@5上均为正增益，说明提升不是偶然点状收益，而是跨数据分布的稳定趋势。

\subsection{代表性差值抽样分析}
本文仅抽取代表性对照做细化分析。对于 GA-LLM（见表\ref{tab:c4-gallm-main}）：在 NYC 上相对最强图基线 ROTAN 的 Acc@1 绝对差值为 \redbf{+0.0882}（0.3988 vs 0.3106）；在 TKY 上相对最强图基线 STHGCN 的差值为 \bluebf{+0.0532}（0.3482 vs 0.2950）；在 CA 上相对 LLM4POI 的差值为 \redbf{+0.0501}（0.2566 vs 0.2065）。这三组对照说明 GA-LLM 的优势同时覆盖“图基线强项场景”和“文本LLM场景”。

对于 TSPM（见表\ref{tab:tspm-main}）：在 Gowalla 上相对最强基线 Graph-Flashback 的 Acc@1 绝对差值为 \bluebf{+0.0083}（0.1595 vs 0.1512），对应 MRR 差值 \bluebf{+0.0087}（0.2509 vs 0.2422）；在 Foursquare 上对应差值为 \bluebf{+0.0127}（Acc@1）与 \bluebf{+0.0165}（MRR）。该结果表明 TSPM 在强基线条件下依然维持稳定正增益，且改进主要体现在“头部命中与排序质量同步提升”。

\subsection{结果分层解读}
从指标层面看，Acc@1与MRR提升说明模型不仅“能命中”，且能把真实目标更稳定地排在前列；Acc@10或Acc@5提升说明候选覆盖范围同步改进。这意味着两条路线并未以牺牲覆盖换取头部精度，而是在多指标上保持一致收益。

从方法层面看，TSPM与GA-LLM分别在“结构稳定性”和“语义泛化”上体现优势，表明“结构约束 + 语义推理”具备明确互补关系。该结论与第\ref{chap:method}章设计目标一致。

\section{机制验证与诊断分析（RQ2--RQ4）}
\subsection{小模型分支消融与诊断（RQ2）}
\subsubsection{核心模块消融}
针对TSPM进行逐项消融，重点比较“去除TSDG”“去除双向转移”等变体。表\ref{tab:ablation}显示：去除任一关键模块均会降低性能，说明小模型增益并非单一组件造成。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{TSPM消融实验（Gowalla）}{Ablation study of TSPM on Gowalla.}
    \label{tab:ablation}
    \begin{tabular}{lcccc}
        \toprule
        方法 & Acc@1 & Acc@5 & Acc@10 & MRR \\
        \midrule
        Flashback & 0.1158 & 0.2754 & 0.3479 & 0.1925 \\
        TSPM \textit{w/o TSDG} & 0.1573 & 0.3488 & 0.4321 & 0.2482 \\
        TSPM \textit{w/o BTM} & 0.1587 & 0.3515 & 0.4338 & 0.2501 \\
        TSPM & \textbf{0.1595} & \textbf{0.3520} & \textbf{0.4350} & \textbf{0.2509} \\
        \bottomrule
    \end{tabular}
\end{table}

该表揭示了两点：第一，TSDG负责将时段异质信息显式结构化，去除后整体能力下降最明显；第二，双向转移建模虽增益幅度略小，但对MRR影响更敏感，说明其在“正确候选前置”上更关键。
进一步按 Acc@1 计算相对提升：完整 TSPM 相比 \textit{w/o TSDG} 为 \redbf{+1.40\%}（0.1595 vs 0.1573），相比 \textit{w/o BTM} 为 \bluebf{+0.50\%}（0.1595 vs 0.1587）。这说明 TSDG 是主增益来源，BTM 是稳定排序质量的补充增益来源。

\subsection{大模型分支消融与诊断（RQ3）}
\subsubsection{GCIM与PAM模块消融}
表\ref{tab:c4-gallm-ablation}展示GA-LLM在三个数据集上的消融结果。去除GCIM带来最大性能回落，说明地理表示建模是LLM路线的基础；去除PAM同样造成稳定下降，说明转移先验注入不可或缺。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{GA-LLM消融实验（Acc@1）}{Ablation study of GA-LLM (Acc@1).}
    \label{tab:c4-gallm-ablation}
    \begin{tabular}{lccc}
        \toprule
        变体 & NYC & TKY & CA \\
        \midrule
        Full Model & \textbf{0.3988} & \textbf{0.3482} & \textbf{0.2566} \\
        \textit{w/o CSE} & 0.3800 & 0.3435 & 0.2467 \\
        \textit{w/o HDE} & 0.3813 & 0.3453 & 0.2423 \\
        \textit{w/o GCIM} & 0.3729 & 0.3370 & 0.2402 \\
        \textit{w/o PAM} & 0.3901 & 0.3468 & 0.2499 \\
        \bottomrule
    \end{tabular}
\end{table}

该结果与机制解释一致：CSE更擅长刻画局部连续变化，HDE更擅长编码稀疏场景下的层级归属，GCIM融合二者后形成稳定地理约束；PAM则负责把结构转移知识对齐到LLM语义空间。
按 Acc@1 的相对提升计算，完整 GA-LLM 相比 \textit{w/o GCIM} 在 NYC/TKY/CA 分别为 \redbf{+6.94\%/+3.32\%/+6.83\%}；相比 \textit{w/o PAM} 分别为 \bluebf{+2.23\%/+0.40\%/+2.68\%}。该结果表明 GCIM 负责主要地理一致性收益，PAM 负责稳定补充收益。

\subsubsection{GCIM细粒度消融与参数实验}
为进一步回答“GCIM的有效性来自哪些设计”，表\ref{tab:c4-gcim-inner-ablation}给出GCIM内部消融结果。可以看到，移除测地对齐损失（GAL）后性能显著下降，说明仅有坐标编码而缺少显式距离一致性约束时，模型仍会出现“语义合理但地理偏离”的预测。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{GCIM内部消融（Acc@1）}{Internal ablation of GCIM (Acc@1).}
    \label{tab:c4-gcim-inner-ablation}
    \begin{tabular}{lcc}
        \toprule
        变体 & NYC & CA \\
        \midrule
        Full Model & \textbf{0.3988} & \textbf{0.2566} \\
        \textit{w/o CSE} & 0.3800 & 0.2467 \\
        \textit{w/o HDE} & 0.3813 & 0.2423 \\
        \textit{w/o GAL} & 0.3809 & 0.2481 \\
        \textit{w/o GCIM} & 0.3729 & 0.2402 \\
        \bottomrule
    \end{tabular}
\end{table}

同时，表\ref{tab:c4-gcim-hparam}展示了层级n-gram深度与Quadkey层级$L$的敏感性。结果表明：$n=6$与$L=25$在NYC与CA上均取得最优折中；当$n$或$L$继续增大时，性能反而下降，说明过深层级会引入冗余与噪声，削弱泛化稳定性。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{GCIM关键超参数实验：n-gram深度与Quadkey层级}{Key hyperparameter study of GCIM: n-gram depth and Quadkey level.}
    \label{tab:c4-gcim-hparam}
    \begin{tabular}{lcccccc}
        \toprule
        设置 & NYC Acc@1 & NYC Acc@5 & NYC MRR@5 & CA Acc@1 & CA Acc@5 & CA MRR@5 \\
        \midrule
        $n=4$ & 0.3476 & 0.5249 & 0.4107 & 0.2198 & 0.3986 & 0.2924 \\
        $n=5$ & 0.3794 & 0.5982 & 0.4451 & 0.2473 & 0.4327 & 0.3185 \\
        $n=6$ & \textbf{0.3988} & \textbf{0.6337} & \textbf{0.4663} & \textbf{0.2566} & \textbf{0.4614} & \textbf{0.3340} \\
        $n=7$ & 0.3763 & 0.5894 & 0.4386 & 0.2371 & 0.4213 & 0.3110 \\
        \midrule
        $L=24$ & 0.3782 & 0.5965 & 0.4438 & 0.2423 & 0.4347 & 0.3191 \\
        $L=25$ & \textbf{0.3988} & \textbf{0.6337} & \textbf{0.4663} & \textbf{0.2566} & \textbf{0.4614} & \textbf{0.3340} \\
        $L=26$ & 0.3734 & 0.5851 & 0.4357 & 0.2408 & 0.4223 & 0.3116 \\
        $L=30$ & 0.3546 & 0.5303 & 0.4220 & 0.2219 & 0.4012 & 0.2957 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{坐标注入与空间误差分析}
\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.20\textheight,keepaspectratio]{fig4_coor_analysis.pdf}
    \bicaption{坐标注入方案对比分析。}{Comparison of coordinate injection strategies.}
    \label{fig:c4-coor}
\end{figure}

图\ref{fig:c4-coor}展示了“坐标注入方式”和“输入开销”对性能的联合影响。横轴为数据集（NYC、CA）；左纵轴为Acc@1（柱状），右纵轴为每次签到平均token数量（红色折线）。柱状三组分别对应：LLM4POI（纯文本坐标基线）、GA-LLM text-geo（文本地理增强）、GA-LLM \textit{w/o PAM}（启用GCIM但不启用PAM）。

从图中可读出两层对比关系：第一层是“同数据集内的横向对比”，即比较三根柱子的高低；第二层是“性能-开销联合对比”，即比较柱高变化与红线变化是否同步。结果表明，结构化地理注入后Acc@1提升明显，而token开销增幅相对可控，说明性能提升并非主要来自“输入变长”，而来自地理表示的有效性提升。

该图支持的机制结论是：GCIM把连续坐标映射为更稳定的可学习地理表示，从而提高空间可分性；即使不启用PAM，GA-LLM也已显著优于纯文本坐标方案。这一证据直接回答RQ3（坐标建模是否有效），并与第\ref{chap:method}章GCIM设计动机一致。

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.20\textheight,keepaspectratio]{fig5_distance_analysis.pdf}
    \bicaption{不同模型配置下的地理距离误差分布分析。}{Distribution analysis of geographic distance errors under different model configurations.}
    \label{fig:c4-distance}
\end{figure}

图\ref{fig:c4-distance}用于回答“模型到底减少了哪类空间错误”。横轴是预测误差的地理距离分桶（从近距离到远距离）；纵轴是每个距离区间的错误样本占比；不同颜色曲线表示不同模型配置（是否启用GCIM/相关模块）。

该图的关键不是看单个点，而是看整条分布曲线形态。启用GCIM后，近距离区间的占比上升，远距离区间占比下降，整体分布重心向左移动。也就是说，错误并未简单减少为“少数样本偶然改善”，而是系统性地把错误从“远跳失真”转为“近邻可达范围内误差”。

这一分布变化直接对应第\ref{chap:method}章的测地一致性约束：模型在语义预测时同步学习空间连续性，抑制不合理远跳。因而该图同时支撑RQ3（GCIM有效性）与RQ4（模块协同的空间收益来源）。

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.20\textheight,keepaspectratio]{fig6_average_distance_analysis.pdf}
    \bicaption{平均地理误差距离对比。}{Comparison of mean geographic error distance.}
    \label{fig:c4-avg-distance}
\end{figure}

图\ref{fig:c4-avg-distance}是对图\ref{fig:c4-distance}分布结论的单值化验证。横轴为数据集/模型配置，纵轴为平均地理误差距离（km），用于直接比较不同方案的整体空间偏差水平。

对比结果显示，加入地理增强模块后平均误差距离在多个数据集上均下降。以CA为例，平均误差由61.38 km降至37.63 km，对应相对下降 \redbf{38.69\%}；TKY也呈同向下降。这说明改进不是只体现在Acc@K这类命中指标，而是实质性缩短了“预测位置到真实位置”的空间距离。

从机制上看，图\ref{fig:c4-distance}给出“误差分布左移”，图\ref{fig:c4-avg-distance}给出“均值同步下降”，两者共同说明GCIM收益具备分布层与统计量层的双重一致性。因此该图是RQ3/RQ4的重要量化补证。

\subsubsection{跨城冷启动分析}
跨城冷启动是检验泛化能力的关键场景。表\ref{tab:c4-cross-city}显示，无论以NYC、TKY还是CA作为训练源，带GCIM的模型在跨城测试中均优于文本LLM基线，说明模型学习到可迁移的空间规律，而非城市特定记忆。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{跨城冷启动结果：LLM4POI与GA-LLM \textit{w/o PAM}（Acc@1）}{Cross-city cold-start results: LLM4POI vs. GA-LLM \textit{w/o PAM} (Acc@1).}
    \label{tab:c4-cross-city}
    \begin{tabular}{llccc}
        \toprule
        模型 & 训练城市 & NYC测试 & TKY测试 & CA测试 \\
        \midrule
        LLM4POI & NYC & 0.3372 & 0.2594 & 0.1885 \\
        LLM4POI & TKY & 0.3463 & 0.3035 & 0.1960 \\
        LLM4POI & CA  & 0.3344 & 0.2600 & 0.2065 \\
        \midrule
        GA-LLM \textit{w/o PAM} & NYC & 0.3901 & 0.3018 & 0.2053 \\
        GA-LLM \textit{w/o PAM} & TKY & \textbf{0.4059} & \textbf{0.3468} & 0.2273 \\
        GA-LLM \textit{w/o PAM} & CA  & 0.3670 & 0.3065 & \textbf{0.2499} \\
        \bottomrule
    \end{tabular}
\end{table}

该表的关键现象是：以TKY为源域训练时对NYC泛化最佳，说明更复杂多样的源域可学到更强的地理迁移特征。

进一步观察跨城失败样例可见，误差主要集中在三类情形：稀疏区域样本不足、长尾类别语义歧义、以及城市功能分布差异导致的概念漂移（concept drift）。其中，稀疏广域场景会放大候选可达性判断难度；类别分布差异会削弱“语义近邻=空间可达”的假设。该现象解释了为何跨城迁移仍有性能回落，也说明后续应引入更强的域自适应机制。

\subsubsection{PAM作用机制分析}
\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.20\textheight,keepaspectratio]{fig7_pam_analysis.pdf}
    \bicaption{PAM模块作用分析。}{Analysis of the PAM module effect.}
    \label{fig:c4-pam}
\end{figure}

图\ref{fig:c4-pam}聚焦“PAM在困难场景是否真正有用”。横轴是不同评测场景（如目标POI缺失、语义冲突等）；纵轴是排序性能指标（Acc@1/Top-K命中类）；不同柱或曲线对应“启用PAM”与“不启用PAM”两组配置。

该图需要分场景读：在常规样本中两组差距有限，而在困难场景中差距显著扩大。以CA缺失目标场景为例，Acc@1由2.85\%提升至4.36\%，相对提升 \redbf{+52.98\%}。这表明PAM不是“平均意义上的小幅增益模块”，而是在最容易失败的样本上提供关键补偿。

对应机制解释是：当输入中缺少直接目标线索时，纯语义token难以恢复可靠转移关系；PAM通过注入POI结构先验，提升候选项在语义空间中的可检索性与可排序性。该图因此直接回答RQ3中“PAM贡献来源”的问题，并为RQ4提供困难场景证据。

表\ref{tab:c4-token-pam}进一步对比“新增POI token”与“PAM对齐”的差异。结论是：仅靠token扩展在稀疏数据上有一定收益，但在高密度城市中收益有限；PAM在两类场景更稳定。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{POI表示方式对比：token策略与PAM策略（Acc@1）}{Comparison of POI representation methods: token strategy vs. PAM strategy (Acc@1).}
    \label{tab:c4-token-pam}
    \begin{tabular}{lcc}
        \toprule
        方法 & NYC & CA \\
        \midrule
        LLM4POI & 0.3372 & 0.2065 \\
        E4SRec（POI token） & 0.3389 & 0.2226 \\
        only PAM & \textbf{0.3729} & \textbf{0.2402} \\
        \bottomrule
    \end{tabular}
\end{table}

此外，表\ref{tab:c4-pam-embedding-source}显示PAM可作为大小模型联动接口：当小模型侧提供不同POI嵌入（TSPM、MTNet、STHGCN、ROTAN）时，大模型侧性能整体保持稳定，其中与TSPM联动时效果最佳。这说明PAM不仅“可兼容”，还能够把更强的时空结构先验有效传递到生成式分支。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{不同POI嵌入来源在PAM中的表现（NYC）}{Performance of different POI embedding sources in PAM (NYC).}
    \label{tab:c4-pam-embedding-source}
    \begin{tabular}{lcc}
        \toprule
        模型变体 & Acc@1 & Acc@5 \\
        \midrule
        GA-LLM-TSPM & \textbf{0.3988} & \textbf{0.6337} \\
        GA-LLM-MTNet & 0.3988 & 0.6335 \\
        GA-LLM-STHGCN & 0.3950 & 0.6256 \\
        GA-LLM-ROTAN & 0.3921 & 0.6162 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{双路线互补性分析（RQ4）}
互补性结论只基于可观测数据，不引入额外假设。第一，TSPM 在母数据集上的稳定提升（如 Gowalla Acc@1 \redbf{+5.49\%}、Foursquare Acc@1 \redbf{+4.53\%}）说明结构分支对时间异质迁移建模有效。第二，GA-LLM 在城市子集上的增益（如 NYC Acc@1 \redbf{+18.27\%}、TKY Acc@5 \redbf{+19.20\%}、CA Acc@5 \redbf{+24.10\%}）说明语义分支在复杂城市分布下具备更强泛化。第三，GCIM 使平均地理误差显著下降、PAM 在缺失目标场景提升 \redbf{+52.98\%}，共同证明“地理一致性 + 转移先验”是 GA-LLM 路线的关键来源。

综合来看，两条路线并非互相替代：TSPM提供稳定时空结构约束，GA-LLM提供跨场景语义泛化能力。该互补关系由表\ref{tab:tspm-main}、表\ref{tab:c4-gallm-main}、表\ref{tab:c4-gallm-ablation}、图\ref{fig:c4-avg-distance}与图\ref{fig:c4-pam}共同支持。

\section{效率与可扩展性分析（RQ5）}
\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.20\textheight,keepaspectratio]{fig8_efficiency_study.pdf}
    \bicaption{效率与资源开销对比分析。}{Comparison of efficiency and resource overhead.}
    \label{fig:c4-efficiency}
\end{figure}

图\ref{fig:c4-efficiency}用于验证“提升是否依赖高成本”。图中联合展示效果指标（如Acc@1）与资源指标（如训练/推理开销、参数或显存），不同点或柱代表不同模型配置。

读图时重点看“帕累托位置”：若某配置在相近开销下精度更高，或在相近精度下降低开销，则说明其效率更优。实验中GA-LLM协同方案位于“较高精度且开销可控”区域，表明其并非依赖全参数微调或超长输入带来的暴力增益。

该结果对应第\ref{chap:method}章复杂度分析：LoRA降低可训练参数规模，结构化注入减少无效文本冗余，共同带来“精度提升-资源可控”的工程可部署性。这一证据直接回答RQ5。

为增强可量化对比，表\ref{tab:c4-eff-summary}归纳了效率研究中的关键现象：GA-LLM相较LLM4POI在保持更高准确率的同时，凭借更紧凑输入与参数高效微调实现更低推理时延。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{效率研究关键结论汇总（定性+已报告趋势）}{Summary of key findings in efficiency study (qualitative trends with reported observations).}
    \label{tab:c4-eff-summary}
    \begin{tabular}{P{0.20\textwidth}P{0.34\textwidth}P{0.34\textwidth}}
        \toprule
        维度 & LLM4POI & GA-LLM \\
        \midrule
        输入开销 & 依赖更长历史文本，token消耗高 & 结构化地理/POI注入，token更紧凑 \\
        训练阶段 & 全流程文本驱动，微调时长较长 & LoRA + 模块化注入，训练效率更高 \\
        推理阶段 & 单次查询时延较高 & 在多数设置下保持更低时延 \\
        部署可行性 & 对资源要求偏高 & 在精度与效率间更平衡 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{模型规模与训练策略实验}
除效率曲线外，我们进一步补充不同LLM规模与训练策略的实验。表\ref{tab:c4-llm-scale}显示，GA-LLM在较小参数规模下仍保持稳定优势，说明本文改进并不依赖“更大模型”才能生效；同时，与不同小模型骨干（尤其TSPM）组合后仍能保持提升，进一步验证了PAM的联动兼容性。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{模型规模与POI骨干组合实验（NYC）}{Experiments on model scale and POI backbone combinations (NYC).}
    \label{tab:c4-llm-scale}
    \begin{tabular}{lccc}
        \toprule
        模型 & Acc@1 & Acc@5 & MRR@5 \\
        \midrule
        GA-LLM(7B) & 0.3988 & 0.6337 & 0.4663 \\
        GA-LLM(3B) & \textbf{0.4070} & \textbf{0.6448} & \textbf{0.4994} \\
        E4SRec & 0.3389 & 0.5534 & 0.4047 \\
        MTNet & 0.2620 & 0.5381 & 0.3855 \\
        GA-LLM-TSPM & 0.3988 & 0.6337 & 0.4663 \\
        GA-LLM-MTNet & 0.3988 & 0.6335 & 0.4662 \\
        STHGCN & 0.2734 & 0.5361 & 0.3915 \\
        GA-LLM-STHGCN & 0.3950 & 0.6256 & 0.4558 \\
        ROTAN & 0.3106 & 0.5281 & 0.4104 \\
        GA-LLM-ROTAN & 0.3921 & 0.6162 & 0.4493 \\
        \bottomrule
    \end{tabular}
\end{table}

表\ref{tab:c4-train-strategy}给出单阶段与两阶段训练对比。在NYC数据集上，单阶段训练略优于两阶段训练。分析其原因：NYC数据量较大且POI分布集中，对齐预热阶段的收益被充分的端到端优化所覆盖；换言之，当训练样本足以支撑联合优化的稳定收敛时，额外的预热阶段引入的信息瓶颈反而限制了最终性能。然而，两阶段策略在数据更稀疏或分布更复杂的场景中仍具有优化稳定性优势（如TKY与CA的消融趋势所示）。因此，本文在方法章保留两阶段作为默认策略，以兼顾不同数据条件下的鲁棒性。

\begin{table}[htbp]
    \tblstyle
    \bitablecaption{训练策略对比（NYC）}{Comparison of training strategies (NYC).}
    \label{tab:c4-train-strategy}
    \begin{tabular}{lcc}
        \toprule
        训练策略 & Acc@1 & Acc@5 \\
        \midrule
        GA-LLM-One Stage & \textbf{0.3988} & \textbf{0.6337} \\
        GA-LLM-Two Stage & 0.3922 & 0.6167 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{部署策略}
以下内容属于工程落地可选方案，不属于本文离线实验协议。本文给出三条可实施策略：
\begin{enumerate}
    \item 采用“GA-LLM直推 + 解码规模控制”的主链路，稳定输出并控制时延；
    \item 对热门区域建立缓存与增量更新机制，减少重复计算；
    \item 在离线周期训练与在线小步更新之间建立联动，平衡新鲜度与稳定性。
\end{enumerate}

\section{本章小结}
本章围绕RQ1--RQ5构建了完整证据链：
\begin{enumerate}
    \item RQ1：表\ref{tab:tspm-main}与表\ref{tab:c4-gallm-main}表明TSPM与GA-LLM两条路线在不同任务设定下均取得稳定提升；
    \item RQ2：表\ref{tab:ablation}验证小模型关键模块均具有独立贡献；
    \item RQ3：表\ref{tab:c4-gallm-ablation}、表\ref{tab:c4-cross-city}及图\ref{fig:c4-coor}至图\ref{fig:c4-pam}表明GCIM与PAM显著提升空间一致性与跨场景泛化；
    \item RQ4：误差分解显示结构建模与语义建模具有可解释互补关系，可针对性降低空间远跳与历史重复两类典型错误；
    \item RQ5：图\ref{fig:c4-efficiency}与表\ref{tab:c4-eff-summary}显示方法在效果与开销之间达到可部署平衡。
\end{enumerate}
综合来看，本章不仅验证了双路线方法在准确率与鲁棒性上的有效性，也通过诊断图与效率分析解释了性能来源及工程代价，形成了从“结果对比”到“机制解释”再到“部署可行性”的完整论证闭环。上述结论为第5章的总体总结与后续研究展望提供了直接实证依据。
