\chapter{相关研究与问题分析}
\label{chap:related}

\section{任务定义与符号约定}
设用户集合为 $\mathcal{U}=\{u_1,u_2,\ldots,u_M\}$，POI集合为 $\mathcal{L}=\{\ell_1,\ell_2,\ldots,\ell_N\}$。用户 $u$ 的第 $i$ 条签到记为
\begin{equation}
x_i=(u,\ell_i,t_i,g_i,c_i),
\label{eq:c2-checkin}
\end{equation}
其中 $\ell_i$ 为POI标识，$t_i$ 为时间戳，$g_i=(lat_i,lon_i)$ 为地理坐标，$c_i$ 为类别语义。用户轨迹表示为
\begin{equation}
\mathcal{T}_u=\{x_1,x_2,\ldots,x_n\},\quad t_1<t_2<\cdots<t_n.
\label{eq:c2-traj}
\end{equation}

Next POI任务可表示为学习映射
\begin{equation}
f:\mathcal{T}_u\mapsto \hat{\ell}_{n+1},\quad \hat{\ell}_{n+1}\in\mathcal{L},
\label{eq:c2-task}
\end{equation}
使真实下一POI $\ell_{n+1}$ 在候选排序中尽可能靠前。若输出Top-$K$列表，记为 $\hat{\mathbf{y}}_u=[\hat{\ell}^{(1)},\ldots,\hat{\ell}^{(K)}]$。

\section{评价指标与实验协议说明}
本文采用 Acc@K、MRR 与 NDCG@K 评价排序质量：
\begin{equation}
\text{Acc@K}=\frac{1}{|\mathcal{D}|}\sum_{n=1}^{|\mathcal{D}|}\mathbf{1}(r_n\le K),
\label{eq:c2-acc}
\end{equation}
\begin{equation}
\text{MRR}=\frac{1}{|\mathcal{D}|}\sum_{n=1}^{|\mathcal{D}|}\frac{1}{r_n},
\label{eq:c2-mrr}
\end{equation}
\begin{equation}
\text{NDCG@K}=\frac{1}{|\mathcal{D}|}\sum_{n=1}^{|\mathcal{D}|}\frac{\mathbf{1}(r_n\le K)}{\log_2(r_n+1)}.
\label{eq:c2-ndcg}
\end{equation}
其中 $r_n$ 为第 $n$ 个样本中真实POI的排名。Acc@K反映命中能力，MRR强调首个正确结果的位置，NDCG@K更关注头部排序质量。

本节仅说明指标含义与使用理由。数据划分、负采样、显著性检验和实现细节统一在第\ref{chap:exp}章给出。

\section{小模型路线综述：序列与图方法}
\subsection{序列建模方法}
FPMC~\cite{FPMC}、PRME~\cite{PRME} 等方法以“偏好建模 + 转移建模”为核心；ST-RNN~\cite{ST-RNN}、HST-LSTM~\cite{HST-LSTM}、LSTPM~\cite{LSTPM}、STAN~\cite{STAN} 将时空上下文与注意力机制引入序列编码；CLSPRec~\cite{CLSPRec}、FHCRec~\cite{FHCRec} 进一步通过对比学习提升稀疏场景鲁棒性。

\textbf{局限与启示：}序列模型对局部行为刻画精细，但在时间异质性显式建模和跨用户高阶迁移利用上仍不足，提示本文需引入“时间分段建模 + 结构化转移先验”。

\subsection{图建模方法}
GETNext~\cite{GETNext}、GraphFlashback~\cite{GraphFlashback}、STHGCN~\cite{STHGCN}、SNPM~\cite{SNPM} 等方法通过POI图或异构图学习高阶关系，缓解稀疏监督问题；ROTAN~\cite{ROTAN}、MTNet~\cite{MTNet} 则强化时间动态建模。

\textbf{局限与启示：}图方法在结构学习上表现突出，但动态图更新成本和异构信息融合复杂度较高，提示本文需在表达能力与可部署性之间做轻量平衡。

\section{大模型路线综述：LLM驱动推荐}
\subsection{LLM在推荐中的应用}
CoLLM~\cite{CoLLM}、CoRAL~\cite{CoRAL}、LLMRec~\cite{LLMRec}、ReLLa~\cite{ReLLa} 等工作验证了LLM在语义理解、长上下文推理和长尾泛化中的潜力；SeCor~\cite{SeCor}、LLaRA~\cite{LLaRA} 进一步展示了LLM在序列推荐中的可行性。

\subsection{LLM在Next POI中的进展}
LLM4POI~\cite{LLM4POI} 将任务转为提示生成，验证了冷启动潜力；GA-LLM~\cite{liu2026gallm} 针对空间幻觉与转移先验缺失提出地理坐标注入与POI对齐机制，显著改善地理一致性。

\textbf{局限与启示：}现有LLM方案普遍面临坐标语义稀疏、空间连续性不足和转移先验注入弱的问题，说明Next POI场景需要“结构先验 + 语义推理”的协同机制，而非纯文本提示。

\section{研究空白与本文建模原则}
基于上述综述，本文将研究空白归纳为以下三点：
\begin{enumerate}
    \item \textbf{Gap-1：} 小模型强结构、弱语义，难以覆盖复杂意图表达与跨场景泛化；
    \item \textbf{Gap-2：} 大模型强语义、弱空间，难以稳定保持地理连续性与可达性约束；
    \item \textbf{Gap-3：} 缺少面向工程部署的统一协同训练方案，难以兼顾效果与成本。
\end{enumerate}

据此提出本文的建模原则：
\begin{enumerate}
    \item \textbf{DP-1（结构先验显式化）：} 在小模型侧显式建模时间异质性与双向转移关系；
    \item \textbf{DP-2（空间语义对齐）：} 在大模型侧引入地理编码与POI结构对齐模块；
    \item \textbf{DP-3（协同训练可部署）：} 通过两阶段训练和参数高效微调实现稳定融合。
\end{enumerate}

相应地，本文联合优化目标写为
\begin{equation}
\mathcal{L}=\mathcal{L}_{\text{small}}+\lambda_1\mathcal{L}_{\text{align}}+\lambda_2\mathcal{L}_{\text{llm}}+\lambda_3\mathcal{L}_{\text{reg}},
\label{eq:c2-joint}
\end{equation}
其中各损失项分别对应时空结构学习、跨模型对齐、生成/分类学习与复杂度控制。

\section{本章小结}
本章给出了全文统一的任务定义与符号体系，梳理了小模型与大模型路线的代表工作，并从“能力互补但缺乏统一协同”这一核心矛盾出发明确了研究空白。下一章将据此详细介绍本文的协同学习方法与实现机制。
